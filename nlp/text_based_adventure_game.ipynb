{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0cfac66161ae91176b189fc5d840229a5daa938976225f5ac7dd7199e440d2efc",
   "display_name": "Python 3.8.8 64-bit ('nlp': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "cfac66161ae91176b189fc5d840229a5daa938976225f5ac7dd7199e440d2efc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ngfuong/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to /home/ngfuong/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "source": [
    "## Word Senses\n",
    "Words can have multiple meanings. WordNet organizes word senses into a structure called synsets.\n",
    "\n",
    "Each word can have multiple synsets, each synset represents a different meaning of that word."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sense 0: bug.n.01\nDefinition: general term for any insect or similar creeping or crawling invertebrate\nSynonyms: ['bug']\nSense 1: bug.n.02\nDefinition: a fault or defect in a computer program, system, or machine\nSynonyms: ['bug', 'glitch']\nSense 2: bug.n.03\nDefinition: a small hidden microphone; for listening secretly\nSynonyms: ['bug']\nSense 3: hemipterous_insect.n.01\nDefinition: insects with sucking mouthparts and forewings thickened and leathery at the base; usually show incomplete metamorphosis\nSynonyms: ['hemipterous insect', 'bug', 'hemipteran', 'hemipteron']\nSense 4: microbe.n.01\nDefinition: a minute life form (especially a disease-causing bacterium); the term is not in technical use\nSynonyms: ['microbe', 'bug', 'germ']\nSense 5: tease.v.01\nDefinition: annoy persistently\nSynonyms: ['tease', 'badger', 'pester', 'bug', 'beleaguer']\nSense 6: wiretap.v.01\nDefinition: tap a telephone or telegraph wire to get information\nSynonyms: ['wiretap', 'tap', 'intercept', 'bug']\n"
     ]
    }
   ],
   "source": [
    "def get_senses(word):\n",
    "    \"\"\"\n",
    "    Returns a list of senses (synsets) of a word\n",
    "    \"\"\"\n",
    "    word_senses = wn.synsets(word)\n",
    "    return word_senses\n",
    "\n",
    "def get_definition(word_sense):\n",
    "    return word_sense.definition()\n",
    "\n",
    "def get_synonyms(word_sense):\n",
    "    synonyms = []\n",
    "    for lemma in word_sense.lemmas():\n",
    "        synonym = lemma.name().replace('_', ' ')\n",
    "        synonyms.append(synonym)\n",
    "    return synonyms\n",
    "\n",
    "# Example: bug\n",
    "word_senses = get_senses(\"bug\")\n",
    "for i, word_sense in enumerate(word_senses):\n",
    "    print(\"Sense %d: %s\" %(i, word_sense.name()))\n",
    "    print(\"Definition:\", get_definition(word_sense))\n",
    "    print(\"Synonyms:\", get_synonyms(word_sense))"
   ]
  },
  {
   "source": [
    "## Hypernyms/Hyponyms\n",
    "For example, red is a specific kind of color, or microbe is a kind of organism. These are example of hyponym relationships. If X is-a Y then X is a hyponym of Y, and Y is a hypernym of X. So red is a hyponym of color and color is a hypernym of red.\n",
    "\n",
    "In WordNet, each word sense (synset) has its own hypernyms and hyponyms."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nSense 0: bug.n.01 (general term for any insect or similar creeping or crawling invertebrate)\nHypernyms:\nbug.n.01 \tis a\t insect.n.01\ninsect.n.01 \tis a\t arthropod.n.01\narthropod.n.01 \tis a\t invertebrate.n.01\ninvertebrate.n.01 \tis a\t animal.n.01\nanimal.n.01 \tis a\t organism.n.01\norganism.n.01 \tis a\t living_thing.n.01\nliving_thing.n.01 \tis a\t whole.n.02\nwhole.n.02 \tis a\t object.n.01\nobject.n.01 \tis a\t physical_entity.n.01\nphysical_entity.n.01 \tis a\t entity.n.01\n\nSense 1: bug.n.02 (a fault or defect in a computer program, system, or machine)\nHypernyms:\nbug.n.02 \tis a\t defect.n.03\ndefect.n.03 \tis a\t imperfection.n.01\nimperfection.n.01 \tis a\t state.n.02\nstate.n.02 \tis a\t attribute.n.02\nattribute.n.02 \tis a\t abstraction.n.06\nabstraction.n.06 \tis a\t entity.n.01\n\nSense 2: bug.n.03 (a small hidden microphone; for listening secretly)\nHypernyms:\nbug.n.03 \tis a\t microphone.n.01\nmicrophone.n.01 \tis a\t electro-acoustic_transducer.n.01\nelectro-acoustic_transducer.n.01 \tis a\t transducer.n.01\ntransducer.n.01 \tis a\t electrical_device.n.01\nelectrical_device.n.01 \tis a\t device.n.01\ndevice.n.01 \tis a\t instrumentality.n.03\ninstrumentality.n.03 \tis a\t artifact.n.01\nartifact.n.01 \tis a\t whole.n.02\nwhole.n.02 \tis a\t object.n.01\nobject.n.01 \tis a\t physical_entity.n.01\nphysical_entity.n.01 \tis a\t entity.n.01\n\nSense 3: hemipterous_insect.n.01 (insects with sucking mouthparts and forewings thickened and leathery at the base; usually show incomplete metamorphosis)\nHypernyms:\nhemipterous_insect.n.01 \tis a\t insect.n.01\ninsect.n.01 \tis a\t arthropod.n.01\narthropod.n.01 \tis a\t invertebrate.n.01\ninvertebrate.n.01 \tis a\t animal.n.01\nanimal.n.01 \tis a\t organism.n.01\norganism.n.01 \tis a\t living_thing.n.01\nliving_thing.n.01 \tis a\t whole.n.02\nwhole.n.02 \tis a\t object.n.01\nobject.n.01 \tis a\t physical_entity.n.01\nphysical_entity.n.01 \tis a\t entity.n.01\n\nSense 4: microbe.n.01 (a minute life form (especially a disease-causing bacterium); the term is not in technical use)\nHypernyms:\nmicrobe.n.01 \tis a\t microorganism.n.01\nmicroorganism.n.01 \tis a\t organism.n.01\norganism.n.01 \tis a\t living_thing.n.01\nliving_thing.n.01 \tis a\t whole.n.02\nwhole.n.02 \tis a\t object.n.01\nobject.n.01 \tis a\t physical_entity.n.01\nphysical_entity.n.01 \tis a\t entity.n.01\n\nSense 5: tease.v.01 (annoy persistently)\nHypernyms:\ntease.v.01 \tis a\t torment.v.02\ntorment.v.02 \tis a\t harass.v.01\nharass.v.01 \tis a\t annoy.v.01\nannoy.v.01 \tis a\t displease.v.01\n\nSense 6: wiretap.v.01 (tap a telephone or telegraph wire to get information)\nHypernyms:\nwiretap.v.01 \tis a\t listen_in.v.02\nlisten_in.v.02 \tis a\t listen.v.01\nlisten.v.01 \tis a\t perceive.v.01\n"
     ]
    }
   ],
   "source": [
    "hyper = lambda s: s.hypernyms()\n",
    "hypo = lambda s: s.hyponyms()\n",
    "\n",
    "def get_hypernyms(word_sense, depth=5):\n",
    "    return list(word_sense.closure(hyper, depth=depth))\n",
    "\n",
    "def get_hyponyms(word_sense, depth=5):\n",
    "    return list(word_sense.closure(hypo, depth=depth))\n",
    "\n",
    "# Example: bug\n",
    "word_senses = get_senses(\"bug\")\n",
    "for i, word_sense in enumerate(word_senses):\n",
    "    \"\"\"\n",
    "    The synset names include a word from the set of synonyms,\n",
    "    plus a POS (n for noun, v for verb) and\n",
    "    the number of the sense (sense 01 is the most common sense)\n",
    "    \"\"\"\n",
    "    print(\"\\nSense %d: %s (%s)\" %(i, word_sense.name(), get_definition(word_sense)))\n",
    "    print(\"Hypernyms:\")\n",
    "    hypernyms = word_sense.hypernyms()\n",
    "    while len(hypernyms)>0:\n",
    "        print(word_sense.name(),\"\\tis a\\t\",hypernyms[0].name())\n",
    "        word_sense = hypernyms[0]\n",
    "        hypernyms = word_sense.hypernyms()"
   ]
  },
  {
   "source": [
    "## Manually annotate Senses and Hypernyms/Hyponyms\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = [\n",
    "    'wear crown'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_synsets(sentences):\n",
    "  \"\"\"This function queries WordNet for each word in a list of sentences,\n",
    "     and asks the user to input a number corresponding to the synset.\"\"\"\n",
    "\n",
    "  word_senses = {}\n",
    "  # Cached selections maps from word string to the previous\n",
    "  # selection for this word (an integer)\n",
    "  cached_selections = {}\n",
    "\n",
    "  for i, sent in enumerate(sentences):\n",
    "    words = word_tokenize(sent.lower())\n",
    "\n",
    "    for word in words:\n",
    "      sysnsets = wn.synsets(word)\n",
    "      if len(sysnsets) != 0:\n",
    "        selection = select_synset(sent, word, sysnsets, cached_selections)\n",
    "        if selection != None:\n",
    "          cached_selections[word] = selection\n",
    "          if selection < len(sysnsets):\n",
    "            s = sysnsets[selection]\n",
    "            word_senses[word] = s.name()\n",
    "  return word_senses\n",
    "\n",
    "\n",
    "def select_synset(sent, word, sysnsets, cached_selections):\n",
    "  \"\"\"Ask the user to select which sense of the word  \n",
    "     is being used in this sentence.\"\"\"\n",
    "  print(sent)\n",
    "  print(word.upper())\n",
    "\n",
    "  prev_selection = -1\n",
    "  if word in cached_selections:\n",
    "    prev_selection = cached_selections[word]\n",
    "\n",
    "  for choice, s in enumerate(sysnsets):\n",
    "    if choice == prev_selection:\n",
    "      print(\"*** \", end = '')\n",
    "    print(\"%d) %s - %s\" % (choice, s.name(), s.definition()))\n",
    "\n",
    "  choice += 1\n",
    "  if choice == prev_selection:\n",
    "    print(\"*** \", end = '')\n",
    "  print(\"%d) None of these.\" % choice)\n",
    "\n",
    "  selection = -1\n",
    "  while selection == -1:\n",
    "    try:\n",
    "      user_input = input(\">\")\n",
    "      if user_input.strip() == 'x':\n",
    "        # The user can press 'x' to exit.\n",
    "        return None\n",
    "      if user_input.strip() == '' and prev_selection > -1:\n",
    "        # The user can press retrun to confirm the previous selection.\n",
    "        return prev_selection\n",
    "      selection = int(user_input)\n",
    "    except:\n",
    "      selection = -1\n",
    "    if selection < 0 or selection > len(sysnsets):\n",
    "      print(\"Please select a number between 0-%d, or type 'x' to exit\" % len(sysnsets))\n",
    "      if prev_selection > -1:\n",
    "        print(\"You can also press return to confirm the previous selection (marked by ***).\")\n",
    "    else:\n",
    "      return selection\n",
    "\n",
    "\n",
    "def confirm_hyponyms(word, sysnset, do_hypernyms_instead=False):\n",
    "  \"\"\"Ask the user to confirm which of the hyponyms are applicable \n",
    "     for this sentence.\"\"\"\n",
    "  print(\"\\n\",word.upper())\n",
    "\n",
    "  confirmed = []\n",
    "  if do_hypernyms_instead:\n",
    "    unconfirmed = sysnset.hypernyms()\n",
    "  else:\n",
    "    unconfirmed = sysnset.hyponyms()\n",
    "\n",
    "  while len(unconfirmed) > 0:\n",
    "    s = unconfirmed.pop(0)\n",
    "    print(\"Is %s an appropriate substitute for %s? (y/n)\" % (s.name(), word))\n",
    "    print(\"It means:\", s.definition())\n",
    "    print(\"Synonyms are:\", get_synonyms(s))\n",
    "    user_input = ''\n",
    "    while user_input == '':\n",
    "      user_input = input(\">\")\n",
    "      user_input = user_input.strip()\n",
    "      if user_input == 'y' or user_input == 'yes':\n",
    "        confirmed.append(s.name())\n",
    "        if do_hypernyms_instead:\n",
    "          unconfirmed.extend(s.hypernyms())\n",
    "        else:\n",
    "          unconfirmed.extend(s.hyponyms())\n",
    "        \n",
    "      elif user_input == 'n' or user_input == 'no':\n",
    "        pass\n",
    "      elif user_input == 'x':\n",
    "        # The user can press 'x' to exit.\n",
    "        return confirmed\n",
    "      else:\n",
    "        print(\"Please type 'yes' or 'no' or 'x' to stop confirming for this word\")\n",
    "        user_input = ''\n",
    "  return confirmed\n",
    "\n",
    "# Save your annotations to a file, so that you can submit them with your homework.\n",
    "def save_to_drive(word_senses, confirmed_hyponyms, confirmed_hypernyms):\n",
    "  import json\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive/')\n",
    "\n",
    "  output_file = '/content/drive/My Drive/word-sense-annotations.json'\n",
    "  output_json = {}\n",
    "  output_json['senses'] = word_senses\n",
    "  output_json['hyponyms'] = confirmed_hyponyms\n",
    "  output_json['hypernyms'] = confirmed_hypernyms\n",
    "\n",
    "  with open(output_file, 'w') as write_file:\n",
    "    write_file.write(json.dumps(output_json, sort_keys=True, indent=4))\n",
    "    write_file.write('\\n')\n",
    "\n",
    "#TODO: Sua loi huhu !!!!!!!!!!!!!!!!!\n",
    "def save_to_file(word_senses, confirmed_hyponyms, confirmed_hypernyms):\n",
    "  import json\n",
    "\n",
    "  output_file = './word-sense-annotations.json'\n",
    "  output_json = {}\n",
    "  output_json['senses'] = word_senses\n",
    "  output_json['hyponyms'] = confirmed_hyponyms\n",
    "  output_json['hypernyms'] = confirmed_hypernyms\n",
    "\n",
    "  with open(output_file, 'w') as f:\n",
    "      json.dump(output_json, f, ensure_ascii=False, sort_keys=True, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "wear crown\n",
      "WEAR\n",
      "0) wear.n.01 - impairment resulting from long use\n",
      "1) clothing.n.01 - a covering designed to be worn on a person's body\n",
      "2) wear.n.03 - the act of having on your person as a covering or adornment\n",
      "3) wear.v.01 - be dressed in\n",
      "4) wear.v.02 - have on one's person\n",
      "5) wear.v.03 - have in one's aspect; wear an expression of one's attitude or personality\n",
      "6) wear.v.04 - deteriorate through use or stress\n",
      "7) wear.v.05 - have or show an appearance of\n",
      "8) wear.v.06 - last and be usable\n",
      "9) break.v.42 - go to pieces\n",
      "10) tire.v.02 - exhaust or get tired through overuse or great strain or stress\n",
      "11) wear.v.09 - put clothing on one's body\n",
      "12) None of these.\n",
      "wear crown\n",
      "CROWN\n",
      "0) crown.n.01 - the Crown (or the reigning monarch) as the symbol of the power and authority of a monarchy\n",
      "1) crown.n.02 - the part of a tooth above the gum that is covered with enamel\n",
      "2) crown.n.03 - a wreath or garland worn on the head to signify victory\n",
      "3) crown.n.04 - an ornamental jeweled headdress signifying sovereignty\n",
      "4) crown.n.05 - the part of a hat (the vertex) that covers the crown of the head\n",
      "5) crown.n.06 - an English coin worth 5 shillings\n",
      "6) crown.n.07 - the upper branches and leaves of a tree or other plant\n",
      "7) peak.n.04 - the top or extreme point of something (usually a mountain or hill)\n",
      "8) pennant.n.01 - the award given to the champion\n",
      "9) pate.n.02 - the top of the head\n",
      "10) crown.n.11 - (dentistry) dental appliance consisting of an artificial crown for a broken or decayed tooth\n",
      "11) crown.n.12 - the center of a cambered road\n",
      "12) crown.v.01 - invest with regal power; enthrone\n",
      "13) crown.v.02 - be the culminating event\n",
      "14) crown.v.03 - form the topmost part of\n",
      "15) crown.v.04 - put an enamel cover on\n",
      "16) None of these.\n",
      "First, pick the word sense for the word 'wear'\n",
      "==========\n",
      "Next, pick which hypernyms of wear.v.01 we should allow players to use.\n",
      "==========\n",
      "Finally, pick which hyponyms of wear.v.01 we should allow players to use.\n",
      "==========\n",
      "WEAR\n",
      "First, pick the word sense for the word 'crown'\n",
      "==========\n",
      "Next, pick which hypernyms of crown.n.01 we should allow players to use.\n",
      "==========\n",
      "Finally, pick which hyponyms of crown.n.01 we should allow players to use.\n",
      "==========\n",
      "CROWN\n",
      "You've done annotating! Saving your annotation to local file ('word-sense-annotations.json')...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Object of type Synset is not JSON serializable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f843fc27c4fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You've done annotating! Saving your annotation to local file ('word-sense-annotations.json')...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0msave_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_sense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfirmed_hyponyms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfirmed_hypernyms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-06e160be1952>\u001b[0m in \u001b[0;36msave_to_file\u001b[0;34m(word_senses, confirmed_hyponyms, confirmed_hypernyms)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m       \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Synset is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# Test cell\n",
    "word_senses = annotate_synsets(commands)\n",
    "confirmed_hyponyms = {}\n",
    "confirmed_hypernyms = {}\n",
    "for word in word_senses:\n",
    "    print(\"First, pick the word sense for the word '%s'\" %word)\n",
    "    print(\"==========\")\n",
    "    word_sense = wn.synset(word_senses[word])\n",
    "    print(\"Next, pick which hypernyms of %s we should allow players to use.\" %word_sense.name())\n",
    "    print(\"==========\")\n",
    "    print(\"Finally, pick which hyponyms of %s we should allow players to use.\" %word_sense.name())\n",
    "    print('==========')\n",
    "    confirmed_hyponyms[word] = confirm_hyponyms(word, word_sense)\n",
    "\n",
    "print(\"You've done annotating! Saving your annotation to local file ('word-sense-annotations.json')...\")\n",
    "#save_to_file(word_sense, confirmed_hyponyms, confirmed_hypernyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = './word-sense-annotations.json'\n",
    "output_json = {}\n",
    "output_json['senses'] = word_senses\n",
    "output_json['hyponyms'] = confirmed_hyponyms\n",
    "output_json['hypernyms'] = confirmed_hypernyms\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(output_json, f, ensure_ascii=False, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}